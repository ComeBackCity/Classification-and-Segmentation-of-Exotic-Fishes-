{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ComeBackCity/ML_Project/blob/main/ML_Project_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gkRlLMnwXyDV",
        "outputId": "a420637e-a33b-4a73-ec91-75c26eaa77b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        " \n",
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QkqLAXLhKr7r"
      },
      "outputs": [],
      "source": [
        "# main part\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.layers.core import  Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import gc\n",
        "from random import sample\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHOJGiQDLM50",
        "outputId": "f443820f-4664-4df7-810c-745b2ca2fd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wywzLq1aMfQe",
        "outputId": "a5514b6c-086b-47ec-f922-337f40527400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n",
            "9000\n",
            "images:  9000  masks:  9000\n"
          ]
        }
      ],
      "source": [
        "# imagePath = r'/content/drive/MyDrive/Xing_Project/MultiResNet/Data/archive/Segmentation/Original'\n",
        "# maskPath = r'/content/drive/MyDrive/Xing_Project/MultiResNet/Data/archive/Segmentation/Mask'\n",
        "# extraPath =  r'/content/drive/MyDrive/Xing_Project/MultiResNet/Data/archive/Segmentation/Extra'\n",
        "imagePath = r'/content/drive/MyDrive/archive/Segmentation/Original'\n",
        "maskPath = r'/content/drive/MyDrive/archive/Segmentation/Mask'\n",
        "extraPath =  r'/content/drive/MyDrive/archive/Segmentation/Extra'\n",
        "imageCnt = 0\n",
        "maskCnt = 0\n",
        "imageFiles = os.listdir(imagePath)\n",
        "maskFiles = os.listdir(maskPath)\n",
        "imageFiles.sort()\n",
        "maskFiles.sort()\n",
        "print(len(imageFiles))\n",
        "print(len(maskFiles))\n",
        "\n",
        "assert len(imageFiles) == len(maskFiles)\n",
        "for i in range(len(imageFiles)):\n",
        "    imageCnt += 1\n",
        "    assert imageFiles[i] == maskFiles[i]\n",
        "    maskCnt += 1\n",
        "print('images:  '+str(imageCnt)+'  masks:  '+str(maskCnt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KeLtCN3ujhz",
        "outputId": "840fed50-6bb4-4d3f-ebd9-0b3fab560c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7200\n",
            "1800\n",
            "\n",
            "7200\n",
            "1800\n"
          ]
        }
      ],
      "source": [
        "# len_data = len(imageFiles) \n",
        "data = imageFiles\n",
        "mask = imageFiles\n",
        "len_data = len(data)\n",
        "\n",
        "all_indices = [i for i in range(len_data)]\n",
        "train_size = int(0.8 * len_data)\n",
        "\n",
        "train_indices = sample(range(len_data),train_size)\n",
        "test_indices = list(set(all_indices) - set(train_indices))\n",
        "\n",
        "# print(train_indices)\n",
        "# print(test_indices)\n",
        "\n",
        "\n",
        "train_images = [data[i] for i in train_indices]\n",
        "test_images = [data[i] for i in test_indices]\n",
        "\n",
        "train_mask = [mask[i] for i in train_indices]\n",
        "test_mask = [mask[i] for i in test_indices]\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(test_images))\n",
        "print()\n",
        "print(len(train_mask))\n",
        "print(len(test_mask))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MktPNjaGjRY1"
      },
      "outputs": [],
      "source": [
        "class Custom_Dataset(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 image_path,\n",
        "                 images,\n",
        "                 mask_path,\n",
        "                 masks,\n",
        "                 batch_size, \n",
        "                 shuffle=True, \n",
        "                 ):\n",
        "        self.images = images\n",
        "        self.image_path = image_path\n",
        "        self.mask_path = mask_path\n",
        "        self.masks = masks\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(math.ceil(len(self.images)/self.batch_size))\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = [i for i in range(len(self.images))]\n",
        "        if self.shuffle == True:\n",
        "            random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate indexes of the batch\n",
        "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        X = []\n",
        "        Y = []\n",
        "\n",
        "        # print(batch_indexes)\n",
        "        for item_index in batch_indexes:\n",
        "            imageFile = self.images[item_index]\n",
        "            maskFile = self.masks[item_index]\n",
        "\n",
        "            # print(imageFile)\n",
        "            # print(maskFile)\n",
        "            assert imageFile == maskFile\n",
        "\n",
        "            if (imageFile.split('.')[-1]=='png'):  \n",
        "\n",
        "                img = cv2.imread('{}/{}'.format(imagePath, imageFile), cv2.IMREAD_COLOR)\n",
        "                resized_img = cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "                X.append(resized_img)\n",
        "\n",
        "                msk = cv2.imread('{}/{}'.format(maskPath,maskFile), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_msk = cv2.resize(msk,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "                Y.append(resized_msk)\n",
        "\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "  \n",
        "        X = X / 255\n",
        "        \n",
        "        Y = Y.reshape((Y.shape[0],Y.shape[1],Y.shape[2],1))\n",
        "        Y = np.round(Y/255,0)\n",
        "        \n",
        "        return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlraBqNOTa94",
        "outputId": "b4454221-becb-47a4-f496-5f6207b7bd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7409.png\n",
            "7409.png\n"
          ]
        }
      ],
      "source": [
        "print(train_images[6731])\n",
        "print(train_mask[6731])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NL-DTyasJmHH"
      },
      "outputs": [],
      "source": [
        "# #Creating training set\n",
        "# print(len(imageFiles))\n",
        "# print(len(maskFiles))\n",
        "\n",
        "# X = []\n",
        "# Y = []\n",
        "# index = 0\n",
        "# for imageFile in tqdm(imageFiles):    \n",
        "#   if (imageFile.split('.')[-1]=='png'):  \n",
        "#     img = cv2.imread('{}/{}'.format(imagePath, imageFile), cv2.IMREAD_COLOR)\n",
        "#     resized_img = cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "#     # X.append(img)\n",
        "    \n",
        "#     X.append(resized_img)\n",
        "    \n",
        "#     msk = cv2.imread('{}/{}'.format(maskPath, maskFiles[index]), cv2.IMREAD_GRAYSCALE)\n",
        "#     resized_msk = cv2.resize(msk,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "#     # Y.append(msk)\n",
        "    \n",
        "#     Y.append(resized_msk)\n",
        "#   index += 1\n",
        "# print(str(len(X)), '  ', str(len(Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7VZVEGUgHabp"
      },
      "outputs": [],
      "source": [
        "train_generator = Custom_Dataset(\n",
        "                    image_path = imagePath,\n",
        "                    images = train_images,\n",
        "                    mask_path = maskPath,\n",
        "                    masks = train_mask,\n",
        "                    batch_size = 32, \n",
        "                    shuffle=True, \n",
        "                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g74nBUZVH_AT",
        "outputId": "d4bd8e45-3e2a-4bc5-8a45-1d927fc15fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1800, 192, 256, 3)\n",
            "(1800, 192, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "test_X = []\n",
        "test_Y = []\n",
        "\n",
        "for image in test_images:\n",
        "\n",
        "    if (image.split('.')[-1]=='png'):  \n",
        "\n",
        "        img = cv2.imread('{}/{}'.format(imagePath, image), cv2.IMREAD_COLOR)\n",
        "        resized_img = cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "        test_X.append(resized_img)\n",
        "\n",
        "        msk = cv2.imread('{}/{}'.format(maskPath,image), cv2.IMREAD_GRAYSCALE)\n",
        "        resized_msk = cv2.resize(msk,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "        test_Y.append(resized_msk)\n",
        "\n",
        "test_X = np.array(test_X)\n",
        "test_Y = np.array(test_Y)\n",
        "\n",
        "test_X = test_X / 255\n",
        "\n",
        "test_Y = test_Y.reshape((test_Y.shape[0],test_Y.shape[1],test_Y.shape[2],1))\n",
        "test_Y = np.round(test_Y/255,0)\n",
        "print(test_X.shape)\n",
        "print(test_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LrlCPWWNUve4"
      },
      "outputs": [],
      "source": [
        "# # preparing testset\n",
        "\n",
        "# print(len(X))\n",
        "# print(len(Y))\n",
        "\n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)\n",
        "\n",
        "# print(X.shape)\n",
        "# print(Y.shape)\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
        "# Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
        "# Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "# del X\n",
        "# del Y\n",
        "# gc.collect()\n",
        "\n",
        "# X_train = X_train / 255\n",
        "# X_test = X_test / 255\n",
        "# Y_train = Y_train / 255\n",
        "# Y_test = Y_test / 255\n",
        "\n",
        "# Y_train = np.round(Y_train,0)\t\n",
        "# Y_test = np.round(Y_test,0)\t\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(Y_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uAcDPJ6hZgq5"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "    \n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer \n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "    \n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QujkZphff4Cz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "    \n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer \n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "    \n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "    \n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x8a-08hFf4ET"
      },
      "outputs": [],
      "source": [
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    MultiRes Block\n",
        "    \n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer \n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-5R33r_rgNFE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "    \n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer \n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eGyPx0_egUOS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def MultiResUnet(height, width, n_channels):\n",
        "    '''\n",
        "    MultiResUNet\n",
        "    \n",
        "    Arguments:\n",
        "        height {int} -- height of image \n",
        "        width {int} -- width of image \n",
        "        n_channels {int} -- number of channels in image\n",
        "    \n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "\n",
        "    current_block = MultiResBlock\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    mresblock1 = current_block(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    # mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = current_block(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    # mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = current_block(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    # mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = current_block(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    # mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = current_block(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(\n",
        "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = current_block(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(\n",
        "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
        "    mresblock7 = current_block(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(\n",
        "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
        "    mresblock8 = current_block(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
        "    mresblock9 = current_block(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fr6a_uOVjDRO"
      },
      "outputs": [],
      "source": [
        "def saveModel(model):\n",
        "\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    '''try:\n",
        "        os.makedirs('models')\n",
        "    except:\n",
        "        pass'''\n",
        "    fileName = extraPath+'/modelP.json' \n",
        "    fp = open(fileName,'w')\n",
        "    fp.write(model_json)\n",
        "    fp.close()\n",
        "    model.save_weights(extraPath+'/modelW.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yBf44hE3UMzp"
      },
      "outputs": [],
      "source": [
        "def loadModel():\n",
        "  fileName = extraPath+'modelP.json'\n",
        "  fp = open(fileName,'r')\n",
        "  model_json = fp.read()\n",
        "  fp.close()\n",
        "  model = model_from_json(model_json)\n",
        "  # load weights into new model\n",
        "  model.load_weights(extraPath+'modelW.h5')\n",
        "  print(\"Loaded model from disk\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4aGUy8Uwkqnw"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "    return intersection/union\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6dyFGgmbkwfz"
      },
      "outputs": [],
      "source": [
        "def evaluateModel(model,X_test,Y_test,batchSize, epoch):\n",
        "    \n",
        "    # try:\n",
        "    #     os.makedirs('./drive/MyDrive/Xing_Project/MultiResNet/results')\n",
        "    # except:\n",
        "    #     pass \n",
        "    \n",
        "\n",
        "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
        "\n",
        "    yp = np.round(yp,0)\n",
        "\n",
        "    for i in range(20):\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(X_test[i])\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
        "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
        "\n",
        "        jacard = (np.sum(intersection)/np.sum(union))  \n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig(extraPath+'/images/'+str(epoch)+'_'+str(i)+'.png',format='png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "    \n",
        "    \n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "        \n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))  \n",
        "\n",
        "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
        "\n",
        "    \n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "    \n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "    \n",
        "    with open(extraPath+'/log.txt','a') as fp:\n",
        "        fp.write(str(jacard)+'\\n')\n",
        "    \n",
        "    with open(extraPath+'/best.txt','r') as fp:\n",
        "        best = fp.read()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        with open(extraPath+'/best.txt','w') as fp:\n",
        "            fp.write(str(jacard))\n",
        "        \n",
        "        saveModel(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6PSwQb_5S-jN"
      },
      "outputs": [],
      "source": [
        "def trainStep(model, train_generator, X_test, Y_test, epochs):\n",
        "\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch : {}'.format(epoch+1))\n",
        "        model.fit(x=train_generator, epochs=1, verbose=1)     \n",
        "\n",
        "        evaluateModel(model,X_test, Y_test,32, epoch)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpCQS9RrlI5x",
        "outputId": "ce3f35a3-a546-4374-c477-d5e7bdf9345b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "225/225 [==============================] - 3842s 17s/step - loss: 0.4208 - accuracy: 0.9707\n",
            "57/57 [==============================] - 14s 237ms/step\n",
            "Jacard Index : 0.24356804211397426\n",
            "Dice Coefficient : 0.3135247770458931\n",
            "***********************************************\n",
            "Jacard Index improved from -1.0 to 0.24356804211397426\n",
            "***********************************************\n",
            "Epoch : 2\n",
            "225/225 [==============================] - 185s 818ms/step - loss: 0.3569 - accuracy: 0.9847\n",
            "57/57 [==============================] - 12s 220ms/step\n",
            "Jacard Index : 0.8491638896742147\n",
            "Dice Coefficient : 0.9143804655496467\n",
            "***********************************************\n",
            "Jacard Index improved from 0.24356804211397426 to 0.8491638896742147\n",
            "***********************************************\n",
            "Epoch : 3\n",
            "225/225 [==============================] - 190s 843ms/step - loss: 0.3118 - accuracy: 0.9873\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.8560594895678196\n",
            "Dice Coefficient : 0.918074567144317\n",
            "***********************************************\n",
            "Jacard Index improved from 0.8491638896742147 to 0.8560594895678196\n",
            "***********************************************\n",
            "Epoch : 4\n",
            "225/225 [==============================] - 191s 848ms/step - loss: 0.2769 - accuracy: 0.9886\n",
            "57/57 [==============================] - 13s 225ms/step\n",
            "Jacard Index : 0.9269604134095947\n",
            "Dice Coefficient : 0.9590637015422383\n",
            "***********************************************\n",
            "Jacard Index improved from 0.8560594895678196 to 0.9269604134095947\n",
            "***********************************************\n",
            "Epoch : 5\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.2496 - accuracy: 0.9897\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9199069320507296\n",
            "Dice Coefficient : 0.9550168853613249\n",
            "Epoch : 6\n",
            "225/225 [==============================] - 192s 851ms/step - loss: 0.2292 - accuracy: 0.9900\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9392149531109447\n",
            "Dice Coefficient : 0.965672118518794\n",
            "***********************************************\n",
            "Jacard Index improved from 0.9269604134095947 to 0.9392149531109447\n",
            "***********************************************\n",
            "Epoch : 7\n",
            "225/225 [==============================] - 192s 851ms/step - loss: 0.2133 - accuracy: 0.9904\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9326943730950102\n",
            "Dice Coefficient : 0.9621429919089812\n",
            "Epoch : 8\n",
            "225/225 [==============================] - 191s 847ms/step - loss: 0.2015 - accuracy: 0.9906\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9412790087257621\n",
            "Dice Coefficient : 0.9668010473540105\n",
            "***********************************************\n",
            "Jacard Index improved from 0.9392149531109447 to 0.9412790087257621\n",
            "***********************************************\n",
            "Epoch : 9\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1925 - accuracy: 0.9907\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9396924961608506\n",
            "Dice Coefficient : 0.9660411804336544\n",
            "Epoch : 10\n",
            "225/225 [==============================] - 191s 847ms/step - loss: 0.1859 - accuracy: 0.9908\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.927039086239081\n",
            "Dice Coefficient : 0.9591675737972294\n",
            "Epoch : 11\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1815 - accuracy: 0.9905\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9399907205838508\n",
            "Dice Coefficient : 0.9662469619224893\n",
            "Epoch : 12\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1778 - accuracy: 0.9908\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9363707795972971\n",
            "Dice Coefficient : 0.9645884976643775\n",
            "Epoch : 13\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1758 - accuracy: 0.9906\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9216041417612572\n",
            "Dice Coefficient : 0.9562528401216055\n",
            "Epoch : 14\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1741 - accuracy: 0.9905\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9119782458417304\n",
            "Dice Coefficient : 0.9510127889188827\n",
            "Epoch : 15\n",
            "225/225 [==============================] - 192s 851ms/step - loss: 0.1729 - accuracy: 0.9906\n",
            "57/57 [==============================] - 13s 225ms/step\n",
            "Jacard Index : 0.9427505109686047\n",
            "Dice Coefficient : 0.9683572299072127\n",
            "***********************************************\n",
            "Jacard Index improved from 0.9412790087257621 to 0.9427505109686047\n",
            "***********************************************\n",
            "Epoch : 16\n",
            "225/225 [==============================] - 192s 849ms/step - loss: 0.1723 - accuracy: 0.9903\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9349608488557732\n",
            "Dice Coefficient : 0.9642051809458535\n",
            "Epoch : 17\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1720 - accuracy: 0.9902\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9303767011640839\n",
            "Dice Coefficient : 0.9607584025182442\n",
            "Epoch : 18\n",
            "225/225 [==============================] - 192s 850ms/step - loss: 0.1714 - accuracy: 0.9904\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9393060981732029\n",
            "Dice Coefficient : 0.9667459914162966\n",
            "Epoch : 19\n",
            "225/225 [==============================] - 192s 851ms/step - loss: 0.1712 - accuracy: 0.9903\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9203709773544899\n",
            "Dice Coefficient : 0.9563968275438907\n",
            "Epoch : 20\n",
            "225/225 [==============================] - 192s 849ms/step - loss: 0.1709 - accuracy: 0.9906\n",
            "57/57 [==============================] - 13s 224ms/step\n",
            "Jacard Index : 0.9305782530679725\n",
            "Dice Coefficient : 0.9624031549520086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f6e96438910>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model = MultiResUnet(height=192, width=256, n_channels=3)\n",
        "#model = loadModel()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #dice_coef, jacard, \n",
        "#model.summary()\n",
        "# saveModel(model)\n",
        "\n",
        "fp = open(extraPath + '/log.txt','w')\n",
        "fp.close()\n",
        "fp = open(extraPath + '/best.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "    \n",
        "trainStep(model, train_generator, test_X, test_Y, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Smp0DxrSjW_U"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1deLE6N1jXAj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MYJE1TU7USUa"
      },
      "outputs": [],
      "source": [
        "# from keras.utils.vis_utils import plot_model\n",
        "# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lkZF-NmdePXn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ML_Project_Segmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}